# Base Configuration File
# This contains common settings shared across all models
# Model-specific configs will extend/override parts of this config

defaults:
  - trainer: default
  - _self_

# --------------------------------------
# General settings
# --------------------------------------
experiment_name: "unconfigured_experiment"
stage: "train"
seed: 42
load_checkpoint_path: null # Only used for prediction and evaluation
execution:
  num_waypoints_to_predict: null
  num_trajectories_to_predict: null
  num_visualized_traj: 20

# --------------------------------------
# Callbacks
# --------------------------------------
callbacks:
  checkpoint:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    dirpath: ".outputs"
    filename: "{epoch}-{val_loss:.2f}"
    monitor: "val_loss"
    mode: "min"
    save_top_k: 1
    save_last: true

  early_stopping:
    _target_: pytorch_lightning.callbacks.EarlyStopping
    monitor: "val_loss"
    mode: "min"
    patience: 5
    min_delta: 0.001

  learning_rate_monitor:
    _target_: pytorch_lightning.callbacks.LearningRateMonitor
    logging_interval: "epoch"

# --------------------------------------
# Data processing
# --------------------------------------
dataloader:
  _target_: torch.utils.data.DataLoader
  batch_size: 3072
  num_workers: 4
  pin_memory: true
  shuffle: true
  drop_last: false

data_processing:
  validation_percentage: 0.2

# --------------------------------------
# Optimizer
# --------------------------------------
optimizer:
  _target_: torch.optim.AdamW
  lr: 0.0001
  weight_decay: 0.01

# --------------------------------------
# Weights and Biases
# --------------------------------------
wandb:
  _target_: pytorch_lightning.loggers.WandbLogger
  project: "Approach Prediction"
  name: ${experiment_name}
  tags: []

# --------------------------------------
# Hydra configuration
# --------------------------------------
hydra:
  run:
    dir: .outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
